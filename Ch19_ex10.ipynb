{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9kCunALG78ofoVlh9FyRK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "10. 하나의 머신에 여러 개의 GPU에서 MirroredStrategy 전략으로 모델을 훈련해보세요(GPU를 준비하지 못하면 코랩의 GPU 런타임을 사용하여 가상 GPU 2개를 만들 수 있습니다). CentralStorageStrategy 전략으로 모델을 다시 훈련하고 훈련 시간을 비교해보세요."
      ],
      "metadata": {
        "id": "Lt92NryuOyba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZL58rN4OnRM",
        "outputId": "e95cc001-704d-4ca2-ca55-28b82975f665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0   2574      0  0:00:01  0:00:01 --:--:--  2574\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:9 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,644 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:13 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,170 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,035 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,561 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,341 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,334 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,208 kB]\n",
            "Fetched 16.8 MB in 12s (1,369 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "26 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 26 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.12.0 [430 MB]\n",
            "Fetched 430 MB in 22s (19.5 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 122400 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.12.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.12.0) ...\n",
            "Setting up tensorflow-model-server (2.12.0) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.4/438.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.7/443.7 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.7/443.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# setting\n",
        "\n",
        "# Python\n",
        "import sys\n",
        "assert sys.version_info >= (3,5)\n",
        "\n",
        "# sklearn\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try: \n",
        "  # tensorflow_version in colab only\n",
        "  %tensorflow_version 2.x\n",
        "  !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "  !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "  !apt update && apt-get install -y tensorflow-model-server\n",
        "  %pip install -q -U tensorflow-serving-api\n",
        "  IS_COLAB = True\n",
        "except Exception:\n",
        "  IS_COLAB = False\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "  print(\"감지된 GPU가 없습니다. GPU가 없으면 LSTM과 CNN이 매우 느릴 수 있습니다.\")\n",
        "  if IS_COLAB:\n",
        "    print(\"런타임 > 런타임 유현 변경 메유를 선택하고 하드웨어 가속기로 GPU를 고르세요.\")\n",
        "\n",
        "# module \n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# consistency\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# graph\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize = 14)\n",
        "mpl.rc('xtick', labelsize = 12)\n",
        "mpl.rc('ytick', labelsize = 12)\n",
        "\n",
        "# save pic\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deploy\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok = True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout = True, fig_extension = \"png\", resolution = 300):\n",
        "  path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "  print(\"그림 저장\")\n",
        "  if tight_layout:\n",
        "    plt.tight_layout()\n",
        "  plt.savefig(path, format = fig_extension, dpi = resolution)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "분산 훈련"
      ],
      "metadata": {
        "id": "r4jXefGAV_3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "많은 모델이 하나의 GPU or CPU에서 훈련될 수 있지만 훈련 속도가 너무 느리면 같은 머신에 있는 여러개의 GPU에 분산할 수 있다. 훈련 속도가 느릴 경우 빠르게 만드는 방법이 몇가지 있다.\n",
        "> 1) 구글 클라우드 AI 플랫폼에 있는 TPU 사용\n",
        "https://cloud.google.com/tpu/docs/intro-to-tpu?hl=ko\n",
        "\n",
        "> 2) GPU를 여러 개 가진 서버 여러 대에서 모델 훈련\n",
        "\n",
        "> 3) 모델 병렬화 사용\n",
        "\n",
        "> 같은 머신에서 GPU 여러 개로 시작한 다음 여러 머신에서 GPU  여러 개 사용"
      ],
      "metadata": {
        "id": "5gEhQUNVI0ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data \n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfLGWHrOYH8G",
        "outputId": "f0dd2b9c-15b6-4ffc-cf0d-e1184c29b39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "3wY0FyLeVmtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  return keras.models.Sequential([\n",
        "      keras.layers.Conv2D(filters = 64, kernel_size = 7, activation = \"relu\",\n",
        "                          padding = \"same\", input_shape = [28, 28, 1]),\n",
        "      keras.layers.MaxPooling2D(pool_size = 2),\n",
        "      keras.layers.Conv2D(filters=128, kernel_size = 3, activation = \"relu\",\n",
        "                          padding = \"same\"),\n",
        "      keras.layers.Conv2D(filters=128, kernel_size = 3, activation = \"relu\",\n",
        "                          padding = \"same\"),\n",
        "      keras.layers.MaxPooling2D(pool_size = 2),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(units = 10, activation = \"softmax\"),\n",
        "  ])"
      ],
      "metadata": {
        "id": "2MlIb8qxWI-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "model = create_model()\n",
        "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = keras.optimizers.SGD(learning_rate = 1e-2),\n",
        "              metrics = [\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs = 10, \n",
        "          validation_data = (X_valid, y_valid), batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N5i2gutXWw_",
        "outputId": "43763924-ca5c-41f6-ca20-954b2468838a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "550/550 [==============================] - 16s 12ms/step - loss: 1.3308 - accuracy: 0.5695 - val_loss: 0.3394 - val_accuracy: 0.9112\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 8s 14ms/step - loss: 0.4596 - accuracy: 0.8593 - val_loss: 0.1948 - val_accuracy: 0.9412\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 6s 12ms/step - loss: 0.3095 - accuracy: 0.9083 - val_loss: 0.1342 - val_accuracy: 0.9590\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.2400 - accuracy: 0.9306 - val_loss: 0.1049 - val_accuracy: 0.9710\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.2010 - accuracy: 0.9423 - val_loss: 0.0916 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 6s 10ms/step - loss: 0.1739 - accuracy: 0.9490 - val_loss: 0.0770 - val_accuracy: 0.9766\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.1546 - accuracy: 0.9550 - val_loss: 0.0741 - val_accuracy: 0.9768\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 5s 10ms/step - loss: 0.1425 - accuracy: 0.9577 - val_loss: 0.0677 - val_accuracy: 0.9804\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 5s 10ms/step - loss: 0.1318 - accuracy: 0.9620 - val_loss: 0.0621 - val_accuracy: 0.9828\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 5s 9ms/step - loss: 0.1216 - accuracy: 0.9644 - val_loss: 0.0582 - val_accuracy: 0.9842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa66100cc70>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* MirroredStrategy\n",
        "\n",
        "> Tensorflow 복잡성을 대신 처리해주는 간단한 분석 전략 API 제공\n",
        "MirroredStrategy: 데이터 병렬화를 사용해 가능한 모든 GPU에서 케라스 모델을 훈련시킨다. \n",
        "\n",
        "> MirroredStrategy() 객체 만들고, scope() 메서드를 호출하여 분산 컨텍스트를 얻는다.\n",
        "이 컨텍스트로 모델 생성과 컴파일 과정을 감싼다. \n",
        "보통 모델처럼 fit() 메서드를 호출한다.\n",
        "\n",
        ">> 내부적으로 tf.keras는 분산을 자동으로 인식한다.\n",
        "\n",
        ">> MirroredStrategy 컨텍스트 안에서 모든 변수와 연산이 가능한 모든 GPU 장치에 복제되어야 하는 것을 알고 있다.\n",
        "\n",
        ">> fit() 메서드는 자동으로 훈련 배치를 모든 복제 모델에 나눈다.\n",
        "\n",
        ">> 배치 크기가 복제 모델의 개수로 나누어 떨어져야 한다."
      ],
      "metadata": {
        "id": "_TJoY2pWKGCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Change the default all-reduce algorithm:\n",
        "#distribution = tf.distribute.MirroredStrategy(\n",
        "#    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "\n",
        "# Specify the list of GPUs to use:\n",
        "#distribution = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
        "\n",
        "# Use the central storage strategy instead:\n",
        "#distribution = tf.distribute.experimental.CentralStorageStrategy()\n",
        "\n",
        "#if IS_COLAB and \"COLAB_TPU_ADDR\" in os.environ:\n",
        "#  tpu_address = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "#else:\n",
        "#  tpu_address = \"\"\n",
        "#resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "#tf.config.experimental_connect_to_cluster(resolver)\n",
        "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#distribution = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "\n",
        "with distribution.scope():\n",
        "  model = create_model()\n",
        "  model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "                optimizer = keras.optimizers.SGD(learning_rate = 1e-2),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "mFCwQa0uYfmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100 # must be divisible by the number of workers\n",
        "model.fit(X_train, y_train, epochs = 10, \n",
        "          validation_data = (X_valid, y_valid), batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKS71pfZZJjX",
        "outputId": "201a0feb-35e6-4dd8-e090-8347629fcb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "550/550 [==============================] - 9s 12ms/step - loss: 1.3323 - accuracy: 0.5696 - val_loss: 0.3459 - val_accuracy: 0.9060\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 6s 10ms/step - loss: 0.4489 - accuracy: 0.8627 - val_loss: 0.1945 - val_accuracy: 0.9448\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 5s 10ms/step - loss: 0.3007 - accuracy: 0.9109 - val_loss: 0.1284 - val_accuracy: 0.9640\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 7s 12ms/step - loss: 0.2301 - accuracy: 0.9331 - val_loss: 0.0994 - val_accuracy: 0.9712\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 6s 12ms/step - loss: 0.1882 - accuracy: 0.9458 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 7s 12ms/step - loss: 0.1677 - accuracy: 0.9515 - val_loss: 0.0742 - val_accuracy: 0.9786\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 8s 14ms/step - loss: 0.1489 - accuracy: 0.9566 - val_loss: 0.0701 - val_accuracy: 0.9800\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 7s 12ms/step - loss: 0.1336 - accuracy: 0.9613 - val_loss: 0.0624 - val_accuracy: 0.9820\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 9s 17ms/step - loss: 0.1233 - accuracy: 0.9644 - val_loss: 0.0604 - val_accuracy: 0.9826\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 7s 12ms/step - loss: 0.1171 - accuracy: 0.9660 - val_loss: 0.0559 - val_accuracy: 0.9838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e402939d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJv09Y1EZfEe",
        "outputId": "1d3127b2-7f7d-4dfd-b753-d2af00c125a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.4251001e-10, 2.9088641e-08, 3.3689443e-07, 3.0173635e-07,\n",
              "        1.9761372e-10, 3.5851899e-09, 3.6592305e-12, 9.9999487e-01,\n",
              "        6.3325223e-10, 4.4634776e-06],\n",
              "       [3.1198788e-08, 2.0205212e-04, 9.9979395e-01, 1.1756342e-06,\n",
              "        7.0201622e-10, 9.8169795e-10, 9.3250094e-08, 3.7634737e-07,\n",
              "        2.2979877e-06, 2.5762759e-10],\n",
              "       [1.5152257e-06, 9.9925452e-01, 1.6152777e-05, 1.9996974e-06,\n",
              "        1.1874104e-04, 3.1586972e-06, 3.4926034e-04, 2.3067753e-04,\n",
              "        1.9584379e-05, 4.4090898e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 훈련 루프_MirroredStrategy\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "K = keras.backend\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with distribution.scope():\n",
        "  model = create_model()\n",
        "  optimizer = keras.optimizers.SGD()\n",
        "\n",
        "with distribution.scope():\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().batch(batch_size)\n",
        "  input_iterator = distribution.make_dataset_iterator(dataset)\n",
        "\n",
        "@tf.function\n",
        "def train_step():\n",
        "  def step_fn(inputs):\n",
        "    X, y = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      Y_proba = model(X)\n",
        "      loss = K.sum(keras.losses.sparse_categorical_crossentropy(y, Y_proba)) / batch_size\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "  per_replica_losses = distribution.experimental_run(step_fn, input_iterator)\n",
        "  mean_loss = distribution.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis = None)\n",
        "  return mean_loss\n",
        "\n",
        "n_epochs = 10\n",
        "with distribution.scope():\n",
        "  input_iterator.initialize()\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "    for iteration in range(len(X_train) // batch_size):\n",
        "      print(\"\\rLoss: {:.3f}\".format(train_step().numpy()), end =\"\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAz69uVPZpYs",
        "outputId": "c4a8e774-3f01-437e-fb0d-604c8db8ad7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py:459: StrategyBase.experimental_run (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use run() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Loss: 0.373\n",
            "Epoch 2/10\n",
            "Loss: 0.282\n",
            "Epoch 3/10\n",
            "Loss: 0.260\n",
            "Epoch 4/10\n",
            "Loss: 0.254\n",
            "Epoch 5/10\n",
            "Loss: 0.248\n",
            "Epoch 6/10\n",
            "Loss: 0.242\n",
            "Epoch 7/10\n",
            "Loss: 0.235\n",
            "Epoch 8/10\n",
            "Loss: 0.230\n",
            "Epoch 9/10\n",
            "Loss: 0.221\n",
            "Epoch 10/10\n",
            "Loss: 0.214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 로드하여 가능한 모든 장치에서 실행하고 싶다면 \n",
        "# 분산 컨텍스트 안에서 keras.models.load_model()호출\n",
        "\n",
        "with distribution.scope():\n",
        "  mirrored_model = keras.models.load_model(\"my_mnist_model.h5\")\n"
      ],
      "metadata": {
        "id": "lVfXnQkkVRm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가능한 GPU 장치 중 일부만 사용하고 싶다면\n",
        "# MirroredStartegy 생성자에 장치 리스트를 전달\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy([\"/gpu:0\", \"/gpu:1\"])"
      ],
      "metadata": {
        "id": "qFfT8wjIVSMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 중앙 집중적인 파라미터로 데이터 병렬화 사용\n",
        "\n",
        "> MirroredStrategy() -> CentralStorageStrategy()\n",
        "\n",
        "> => tf.distribute.experimental.CentralStorageStrategy()"
      ],
      "metadata": {
        "id": "Y0xQrqDqS9Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 훈련 루프_CentralStorageStrategy\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "K = keras.backend\n",
        "\n",
        "distribution = tf.distribute.experimental.CentralStorageStrategy()\n",
        "# distribution = tf.distribute.MirroredStrategy() => experimental.CentralStorageStrategy()\n",
        "\n",
        "with distribution.scope():\n",
        "  model = create_model()\n",
        "  optimizer = keras.optimizers.SGD()\n",
        "\n",
        "with distribution.scope():\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().batch(batch_size)\n",
        "  input_iterator = distribution.make_dataset_iterator(dataset)\n",
        "\n",
        "@tf.function\n",
        "def train_step():\n",
        "  def step_fn(inputs):\n",
        "    X, y = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      Y_proba = model(X)\n",
        "      loss = K.sum(keras.losses.sparse_categorical_crossentropy(y, Y_proba)) / batch_size\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "  per_replica_losses = distribution.experimental_run(step_fn, input_iterator)\n",
        "  mean_loss = distribution.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis = None)\n",
        "  return mean_loss\n",
        "\n",
        "n_epochs = 10\n",
        "with distribution.scope():\n",
        "  input_iterator.initialize()\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "    for iteration in range(len(X_train) // batch_size):\n",
        "      print(\"\\rLoss: {:.3f}\".format(train_step().numpy()), end =\"\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNFjVJtIcuu8",
        "outputId": "3191061a-81be-4fae-9f54-d4ef3f702552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-d481d1c3dd6c>:37: DistributedIteratorV1.initialize (from tensorflow.python.distribute.v1.input_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the iterator's `initializer` property instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py:459: StrategyBase.experimental_run (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use run() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Loss: 0.406\n",
            "Epoch 2/10\n",
            "Loss: 0.304\n",
            "Epoch 3/10\n",
            "Loss: 0.282\n",
            "Epoch 4/10\n",
            "Loss: 0.272\n",
            "Epoch 5/10\n",
            "Loss: 0.268\n",
            "Epoch 6/10\n",
            "Loss: 0.263\n",
            "Epoch 7/10\n",
            "Loss: 0.259\n",
            "Epoch 8/10\n",
            "Loss: 0.253\n",
            "Epoch 9/10\n",
            "Loss: 0.247\n",
            "Epoch 10/10\n",
            "Loss: 0.241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yGfBu_icSml_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}